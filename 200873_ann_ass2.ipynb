{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YGw0z4LL7bUE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from librosa import display\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia_dra8mIg9I"
      },
      "source": [
        "#Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5PGCA7woIgY-"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/dataset_a2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rah1txtkJGTx"
      },
      "outputs": [],
      "source": [
        "x_train = np.load('/content/drive/MyDrive/dataset_a2/x_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eXlYylLHJGQX"
      },
      "outputs": [],
      "source": [
        "x_test = np.load('/content/drive/MyDrive/dataset_a2/x_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fHgy5Q5wJGN7"
      },
      "outputs": [],
      "source": [
        "y_train = np.load('/content/drive/MyDrive/dataset_a2/y_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SMdmkqsSJGLK"
      },
      "outputs": [],
      "source": [
        "y_test = np.load('/content/drive/MyDrive/dataset_a2/y_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T90LKGkWPaB7",
        "outputId": "9f8bf4b3-8cdf-4693-e1bd-e58ca007c11d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8000, 64, 1000, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9b5ezMIJzMG",
        "outputId": "c7385bb2-0403-488f-82bc-85105dfe481f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8000, 10)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I07i3StJy3N",
        "outputId": "8aa476a3-bf8d-4949-9a26-d6929b8d0143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 64, 1000, 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPUOJaXeJy0G",
        "outputId": "468c44f2-6101-40cd-f8cd-5c00e47eb545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 10)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r_FYuOYMMSOL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation\n",
        "from sklearn import metrics\n",
        "from tensorflow import keras\n",
        "from keras.layers import Bidirectional, TimeDistributed,SpatialDropout2D, MaxPool2D, Input, GRU, LSTM,Dense, Activation, Dropout,Flatten, Reshape, Permute\n",
        "from keras.layers import BatchNormalization,ZeroPadding1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRK3sbNjWTB6"
      },
      "source": [
        "#ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppjw0WMgWVhc",
        "outputId": "46d3eb3f-252d-43ca-f055-46e1c932b6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 64000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2048032   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32)               128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1152      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,051,410\n",
            "Trainable params: 2,051,074\n",
            "Non-trainable params: 336\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten( input_shape=(64,1000,1)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fP19fnGFkspY"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFGKYPJRk1jU",
        "outputId": "044e1d40-5fec-43b0-be30-81d2069febe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "63/63 [==============================] - 7s 23ms/step - loss: 0.6678 - accuracy: 0.0936\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.4938 - accuracy: 0.1119\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.3936 - accuracy: 0.1124\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.3777 - accuracy: 0.1124\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3757 - accuracy: 0.1124\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3735 - accuracy: 0.1124\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.3712 - accuracy: 0.1125\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3680 - accuracy: 0.1126\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.3641 - accuracy: 0.1125\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3607 - accuracy: 0.1130\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.3562 - accuracy: 0.1139\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3514 - accuracy: 0.1139\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3459 - accuracy: 0.1154\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.3424 - accuracy: 0.1156\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.3365 - accuracy: 0.1171\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.3303 - accuracy: 0.1189\n",
            "Epoch 17/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3235 - accuracy: 0.1219\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3206 - accuracy: 0.1211\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3148 - accuracy: 0.1243\n",
            "Epoch 20/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.3111 - accuracy: 0.1274\n",
            "Epoch 21/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.3073 - accuracy: 0.1268\n",
            "Epoch 22/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2999 - accuracy: 0.1332\n",
            "Epoch 23/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2965 - accuracy: 0.1349\n",
            "Epoch 24/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2905 - accuracy: 0.1385\n",
            "Epoch 25/200\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 0.2835 - accuracy: 0.1452\n",
            "Epoch 26/200\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2823 - accuracy: 0.1450\n",
            "Epoch 27/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2797 - accuracy: 0.1468\n",
            "Epoch 28/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2701 - accuracy: 0.1610\n",
            "Epoch 29/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.2680 - accuracy: 0.1632\n",
            "Epoch 30/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2657 - accuracy: 0.1579\n",
            "Epoch 31/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.2605 - accuracy: 0.1664\n",
            "Epoch 32/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.2573 - accuracy: 0.1692\n",
            "Epoch 33/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2487 - accuracy: 0.1824\n",
            "Epoch 34/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2510 - accuracy: 0.1829\n",
            "Epoch 35/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2461 - accuracy: 0.1842\n",
            "Epoch 36/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2422 - accuracy: 0.1963\n",
            "Epoch 37/200\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.2367 - accuracy: 0.1961\n",
            "Epoch 38/200\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.2362 - accuracy: 0.1970\n",
            "Epoch 39/200\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.2298 - accuracy: 0.2159\n",
            "Epoch 40/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.2301 - accuracy: 0.2124\n",
            "Epoch 41/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2227 - accuracy: 0.2186\n",
            "Epoch 42/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.2210 - accuracy: 0.2226\n",
            "Epoch 43/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.2193 - accuracy: 0.2259\n",
            "Epoch 44/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2183 - accuracy: 0.2315\n",
            "Epoch 45/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2085 - accuracy: 0.2404\n",
            "Epoch 46/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2054 - accuracy: 0.2479\n",
            "Epoch 47/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2041 - accuracy: 0.2550\n",
            "Epoch 48/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2021 - accuracy: 0.2540\n",
            "Epoch 49/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2000 - accuracy: 0.2567\n",
            "Epoch 50/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1954 - accuracy: 0.2625\n",
            "Epoch 51/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1993 - accuracy: 0.2594\n",
            "Epoch 52/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1905 - accuracy: 0.2660\n",
            "Epoch 53/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1864 - accuracy: 0.2766\n",
            "Epoch 54/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1846 - accuracy: 0.2894\n",
            "Epoch 55/200\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.1878 - accuracy: 0.2759\n",
            "Epoch 56/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1857 - accuracy: 0.2876\n",
            "Epoch 57/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1790 - accuracy: 0.2880\n",
            "Epoch 58/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1780 - accuracy: 0.2892\n",
            "Epoch 59/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1776 - accuracy: 0.2960\n",
            "Epoch 60/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1735 - accuracy: 0.2930\n",
            "Epoch 61/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1727 - accuracy: 0.2940\n",
            "Epoch 62/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1738 - accuracy: 0.2984\n",
            "Epoch 63/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1687 - accuracy: 0.3043\n",
            "Epoch 64/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1688 - accuracy: 0.3029\n",
            "Epoch 65/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1639 - accuracy: 0.3029\n",
            "Epoch 66/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1664 - accuracy: 0.3083\n",
            "Epoch 67/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1592 - accuracy: 0.3059\n",
            "Epoch 68/200\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.1600 - accuracy: 0.3140\n",
            "Epoch 69/200\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1553 - accuracy: 0.3146\n",
            "Epoch 70/200\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 0.1571 - accuracy: 0.3166\n",
            "Epoch 71/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1611 - accuracy: 0.3088\n",
            "Epoch 72/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1542 - accuracy: 0.3204\n",
            "Epoch 73/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1520 - accuracy: 0.3234\n",
            "Epoch 74/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1517 - accuracy: 0.3170\n",
            "Epoch 75/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1496 - accuracy: 0.3254\n",
            "Epoch 76/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1472 - accuracy: 0.3211\n",
            "Epoch 77/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1478 - accuracy: 0.3298\n",
            "Epoch 78/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1472 - accuracy: 0.3215\n",
            "Epoch 79/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1460 - accuracy: 0.3221\n",
            "Epoch 80/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1406 - accuracy: 0.3277\n",
            "Epoch 81/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1398 - accuracy: 0.3364\n",
            "Epoch 82/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1467 - accuracy: 0.3302\n",
            "Epoch 83/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1448 - accuracy: 0.3388\n",
            "Epoch 84/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1405 - accuracy: 0.3309\n",
            "Epoch 85/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1499 - accuracy: 0.3349\n",
            "Epoch 86/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1362 - accuracy: 0.3289\n",
            "Epoch 87/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1305 - accuracy: 0.3541\n",
            "Epoch 88/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1290 - accuracy: 0.3535\n",
            "Epoch 89/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1324 - accuracy: 0.3360\n",
            "Epoch 90/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1420 - accuracy: 0.3335\n",
            "Epoch 91/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1348 - accuracy: 0.3506\n",
            "Epoch 92/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1304 - accuracy: 0.3479\n",
            "Epoch 93/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1298 - accuracy: 0.3529\n",
            "Epoch 94/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1308 - accuracy: 0.3406\n",
            "Epoch 95/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1293 - accuracy: 0.3422\n",
            "Epoch 96/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1278 - accuracy: 0.3444\n",
            "Epoch 97/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1304 - accuracy: 0.3456\n",
            "Epoch 98/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1305 - accuracy: 0.3485\n",
            "Epoch 99/200\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1228 - accuracy: 0.3580\n",
            "Epoch 100/200\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.1227 - accuracy: 0.3549\n",
            "Epoch 101/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1268 - accuracy: 0.3568\n",
            "Epoch 102/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1236 - accuracy: 0.3535\n",
            "Epoch 103/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1201 - accuracy: 0.3614\n",
            "Epoch 104/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1205 - accuracy: 0.3504\n",
            "Epoch 105/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1170 - accuracy: 0.3523\n",
            "Epoch 106/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1155 - accuracy: 0.3680\n",
            "Epoch 107/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1176 - accuracy: 0.3553\n",
            "Epoch 108/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1180 - accuracy: 0.3605\n",
            "Epoch 109/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1180 - accuracy: 0.3507\n",
            "Epoch 110/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1157 - accuracy: 0.3551\n",
            "Epoch 111/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1301 - accuracy: 0.3481\n",
            "Epoch 112/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1164 - accuracy: 0.3559\n",
            "Epoch 113/200\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1145 - accuracy: 0.3540\n",
            "Epoch 114/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1182 - accuracy: 0.3565\n",
            "Epoch 115/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1139 - accuracy: 0.3581\n",
            "Epoch 116/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1122 - accuracy: 0.3677\n",
            "Epoch 117/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1141 - accuracy: 0.3600\n",
            "Epoch 118/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1123 - accuracy: 0.3582\n",
            "Epoch 119/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1108 - accuracy: 0.3618\n",
            "Epoch 120/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1127 - accuracy: 0.3640\n",
            "Epoch 121/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1087 - accuracy: 0.3606\n",
            "Epoch 122/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1060 - accuracy: 0.3626\n",
            "Epoch 123/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1073 - accuracy: 0.3711\n",
            "Epoch 124/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1149 - accuracy: 0.3618\n",
            "Epoch 125/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1106 - accuracy: 0.3635\n",
            "Epoch 126/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1135 - accuracy: 0.3573\n",
            "Epoch 127/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1086 - accuracy: 0.3680\n",
            "Epoch 128/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1057 - accuracy: 0.3721\n",
            "Epoch 129/200\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.1076 - accuracy: 0.3699\n",
            "Epoch 130/200\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1092 - accuracy: 0.3629\n",
            "Epoch 131/200\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.1036 - accuracy: 0.3706\n",
            "Epoch 132/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1048 - accuracy: 0.3672\n",
            "Epoch 133/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1009 - accuracy: 0.3786\n",
            "Epoch 134/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1020 - accuracy: 0.3776\n",
            "Epoch 135/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0989 - accuracy: 0.3750\n",
            "Epoch 136/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0980 - accuracy: 0.3835\n",
            "Epoch 137/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1035 - accuracy: 0.3754\n",
            "Epoch 138/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1011 - accuracy: 0.3726\n",
            "Epoch 139/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0933 - accuracy: 0.3926\n",
            "Epoch 140/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1035 - accuracy: 0.3652\n",
            "Epoch 141/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1032 - accuracy: 0.3684\n",
            "Epoch 142/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1027 - accuracy: 0.3808\n",
            "Epoch 143/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1063 - accuracy: 0.3618\n",
            "Epoch 144/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1047 - accuracy: 0.3738\n",
            "Epoch 145/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0963 - accuracy: 0.3780\n",
            "Epoch 146/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0981 - accuracy: 0.3779\n",
            "Epoch 147/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1042 - accuracy: 0.3688\n",
            "Epoch 148/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0929 - accuracy: 0.3855\n",
            "Epoch 149/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0901 - accuracy: 0.3865\n",
            "Epoch 150/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0920 - accuracy: 0.3817\n",
            "Epoch 151/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0966 - accuracy: 0.3805\n",
            "Epoch 152/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0975 - accuracy: 0.3814\n",
            "Epoch 153/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0980 - accuracy: 0.3699\n",
            "Epoch 154/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0921 - accuracy: 0.3844\n",
            "Epoch 155/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0943 - accuracy: 0.3729\n",
            "Epoch 156/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0959 - accuracy: 0.3765\n",
            "Epoch 157/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0926 - accuracy: 0.3790\n",
            "Epoch 158/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0960 - accuracy: 0.3786\n",
            "Epoch 159/200\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.0939 - accuracy: 0.3775\n",
            "Epoch 160/200\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0920 - accuracy: 0.3784\n",
            "Epoch 161/200\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.0875 - accuracy: 0.3860\n",
            "Epoch 162/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0912 - accuracy: 0.3814\n",
            "Epoch 163/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0976 - accuracy: 0.3762\n",
            "Epoch 164/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0891 - accuracy: 0.3812\n",
            "Epoch 165/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0901 - accuracy: 0.3894\n",
            "Epoch 166/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0905 - accuracy: 0.3882\n",
            "Epoch 167/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0827 - accuracy: 0.3881\n",
            "Epoch 168/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0871 - accuracy: 0.3893\n",
            "Epoch 169/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0865 - accuracy: 0.3924\n",
            "Epoch 170/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0900 - accuracy: 0.3816\n",
            "Epoch 171/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0852 - accuracy: 0.3910\n",
            "Epoch 172/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0833 - accuracy: 0.4002\n",
            "Epoch 173/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0853 - accuracy: 0.3831\n",
            "Epoch 174/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0888 - accuracy: 0.3804\n",
            "Epoch 175/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0870 - accuracy: 0.3780\n",
            "Epoch 176/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0811 - accuracy: 0.3864\n",
            "Epoch 177/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0856 - accuracy: 0.3859\n",
            "Epoch 178/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0880 - accuracy: 0.3796\n",
            "Epoch 179/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0892 - accuracy: 0.3755\n",
            "Epoch 180/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0900 - accuracy: 0.3865\n",
            "Epoch 181/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0829 - accuracy: 0.3844\n",
            "Epoch 182/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0823 - accuracy: 0.3830\n",
            "Epoch 183/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0830 - accuracy: 0.3927\n",
            "Epoch 184/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0838 - accuracy: 0.3803\n",
            "Epoch 185/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0862 - accuracy: 0.3828\n",
            "Epoch 186/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0807 - accuracy: 0.3865\n",
            "Epoch 187/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0873 - accuracy: 0.3814\n",
            "Epoch 188/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0832 - accuracy: 0.3866\n",
            "Epoch 189/200\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.0812 - accuracy: 0.3877\n",
            "Epoch 190/200\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0831 - accuracy: 0.3900\n",
            "Epoch 191/200\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.0858 - accuracy: 0.3879\n",
            "Epoch 192/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0847 - accuracy: 0.3876\n",
            "Epoch 193/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0807 - accuracy: 0.3856\n",
            "Epoch 194/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0787 - accuracy: 0.3941\n",
            "Epoch 195/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0825 - accuracy: 0.3814\n",
            "Epoch 196/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0838 - accuracy: 0.3796\n",
            "Epoch 197/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0800 - accuracy: 0.3805\n",
            "Epoch 198/200\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0783 - accuracy: 0.3991\n",
            "Epoch 199/200\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.0801 - accuracy: 0.3816\n",
            "Epoch 200/200\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.0801 - accuracy: 0.3785\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f80103d20d0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=200, batch_size = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AzQGkha3PpWy",
        "outputId": "33fcd334-a301-49f2-ce4b-6199200b170e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uS8bfv_oSKNk",
        "outputId": "b65b5720-9515-413c-c15d-b94a26ed1210"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive'\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gng1kcWpSdvr"
      },
      "outputs": [],
      "source": [
        "model.save('ann')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48sZS0X2bqh7"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3x-yg2n7w2La"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Krc6WDgDuyIQ"
      },
      "outputs": [],
      "source": [
        "for i in range (len(y_pred)) :\n",
        "  for j in range (10):\n",
        "    if y_pred[i,j] >=0.5 :\n",
        "      y_pred[i,j] = 1\n",
        "    else :\n",
        "      y_pred[i,j] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyPIagK5OxU5",
        "outputId": "49361c18-778c-48db-8b69-7e367a11586f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4975410819239535\n"
          ]
        }
      ],
      "source": [
        "# print(f1_score(y_test, y_pred, average = 'micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zAJLORwgUP9L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DN24sbDEUYQc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Ia_dra8mIg9I"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb7837b90114a9796f88f5c44ab04f2f1aa4f30584d8aa74a4612e3afe72275d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
